{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# from spektral.layers import GraphConv\n",
    "# GRaphConv is deprecated, use GCNConv or GCSConv instead\n",
    "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
    "from spektral.utils import normalized_laplacian\n",
    "from spektral.layers import GCSConv  # as GraphConv\n",
    "from spektral.layers import GINConv # as GraphConv\n",
    "from spektral.layers import GCNConv  # as GraphConv\n",
    "\n",
    "from spektral.utils.convolution import gcn_filter  # For GCNConv\n",
    "from spektral.utils.convolution import normalized_adjacency  # For GCSConv\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "l2_reg = 5e-4  # Regularization rate for l2\n",
    "learning_rate = 1e-3  # Learning rate for SGD\n",
    "batch_size = 32  # Batch size\n",
    "epochs = 5  # Number of training epochs\n",
    "es_patience = 200  # Patience fot early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = pathlib.Path().absolute()\n",
    "path = current_path.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_path = path / 'angry_meshpoints'\n",
    "disgusted_path = path / 'disgusted_meshpoints'\n",
    "happy_path = path / 'happy_meshpoints'\n",
    "neutral_path = path / 'neutral_meshpoints'\n",
    "sad_path = path / 'sad_meshpoints'\n",
    "surprised_path = path / 'surprised_meshpoints'\n",
    "\n",
    "path_list = [angry_path, disgusted_path, happy_path, neutral_path, sad_path, surprised_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai_dist(path_list, meshs_list, limit=0.1):\n",
    "    for path in path_list:\n",
    "        quant_files = len(os.listdir(path))\n",
    "        count = 0\n",
    "        for file in os.listdir(path):\n",
    "            if (count / quant_files) > limit:\n",
    "                break\n",
    "            file_path = path / file\n",
    "            count += 1\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                meshs_list[path_list.index(path)].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446\n",
      "161\n",
      "810\n",
      "687\n",
      "742\n",
      "402\n"
     ]
    }
   ],
   "source": [
    "meshs_surprised = []\n",
    "meshs_disgusted = []\n",
    "meshs_happy = []\n",
    "meshs_neutral = []\n",
    "meshs_sad = []\n",
    "meshs_angry = []\n",
    "\n",
    "meshs_list = [meshs_angry, meshs_disgusted, meshs_happy, meshs_neutral, meshs_sad, meshs_surprised]\n",
    "\n",
    "extrai_dist(path_list, meshs_list, 0.1)\n",
    "\n",
    "print(len(meshs_angry))\n",
    "print(len(meshs_disgusted))\n",
    "print(len(meshs_happy))\n",
    "print(len(meshs_neutral))\n",
    "print(len(meshs_sad))\n",
    "print(len(meshs_surprised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meshs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import concat from tensorflow\n",
    "from tensorflow import concat\n",
    "tensor_mesh = concat(meshs_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3248, 478, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mesh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target list\n",
    "target_list = []\n",
    "for i in range(6):\n",
    "    target_list.append(np.full(len(meshs_list[i]), i))\n",
    "\n",
    "target_list = concat(target_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3248])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 6  # Number of classes\n",
    "N = tensor_mesh.shape[-2]  # Number of nodes in the graphs\n",
    "F = tensor_mesh.shape[-1]  # Original feature dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Até aqui está exatamente como o professor sugeriu\n",
    "\n",
    "## um tensor com 3 dimensões: (número de amostras, número de vértices, número de atributos)\n",
    "## Outro com o target: (classe de cada amostra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINConv Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://graphneural.network/layers/convolution/#ginconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = tf.sparse.from_dense(tf.convert_to_tensor(get_mediapipe_adjacency_matrix()))\n",
    "\n",
    "X_in = Input(shape=(N, F))\n",
    "\n",
    "graph_conv_1 = GINConv(32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True)([X_in, adj])\n",
    "graph_conv_2 = GINConv(32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True)([graph_conv_1, adj])\n",
    "flatten = Flatten()(graph_conv_2)\n",
    "fc = Dense(512, activation=\"relu\")(flatten)\n",
    "output = Dense(n_out, activation=\"softmax\")(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = Model(inputs=X_in, outputs=output)\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 478, 2)]          0         \n",
      "                                                                 \n",
      " gin_conv (GINConv)          (None, 478, 32)           97        \n",
      "                                                                 \n",
      " gin_conv_1 (GINConv)        (None, 478, 32)           1057      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15296)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               7832064   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7836296 (29.89 MB)\n",
      "Trainable params: 7836296 (29.89 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still need to figure out how to use the GINConv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "82/82 [==============================] - 6s 62ms/step - loss: 1092.3715 - acc: 0.2502 - val_loss: 501.1785 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 78.6376 - acc: 0.2460 - val_loss: 343.1255 - val_acc: 0.0385\n",
      "Epoch 3/5\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 25.7554 - acc: 0.2691 - val_loss: 223.1945 - val_acc: 0.0108\n",
      "Epoch 4/5\n",
      "82/82 [==============================] - 4s 55ms/step - loss: 30.9525 - acc: 0.2537 - val_loss: 30.2374 - val_acc: 0.0123\n",
      "Epoch 5/5\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 4.4100 - acc: 0.3122 - val_loss: 23.9461 - val_acc: 0.1092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a7fbc4c850>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o tensor_mesh é um tensor de dimensão 3\n",
    "# o sparse_matrix é um tensor de dimensão 2\n",
    "# o target_list é um tensor de dimensão 1\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    tensor_mesh,\n",
    "    target_list,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(patience=es_patience)],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
