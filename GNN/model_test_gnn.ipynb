{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# from spektral.layers import GraphConv\n",
    "# GRaphConv is deprecated, use GCNConv or GCSConv instead\n",
    "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
    "from spektral.utils import normalized_laplacian\n",
    "from spektral.layers import GCSConv  # as GraphConv\n",
    "from spektral.layers import GINConv # as GraphConv\n",
    "from spektral.layers import GCNConv  # as GraphConv\n",
    "\n",
    "from spektral.utils.convolution import gcn_filter  # For GCNConv\n",
    "from spektral.utils.convolution import normalized_adjacency  # For GCSConv\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "l2_reg = 5e-4  # Regularization rate for l2\n",
    "learning_rate = 1e-3  # Learning rate for SGD\n",
    "batch_size = 32  # Batch size\n",
    "epochs = 5  # Number of training epochs\n",
    "es_patience = 200  # Patience fot early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = pathlib.Path().absolute()\n",
    "path = current_path.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_path = path / 'angry_meshpoints'\n",
    "disgusted_path = path / 'disgusted_meshpoints'\n",
    "happy_path = path / 'happy_meshpoints'\n",
    "neutral_path = path / 'neutral_meshpoints'\n",
    "sad_path = path / 'sad_meshpoints'\n",
    "surprised_path = path / 'surprised_meshpoints'\n",
    "\n",
    "path_list = [angry_path, disgusted_path, happy_path, neutral_path, sad_path, surprised_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai_dist(path_list, meshs_list, limit=0.1):\n",
    "    for path in path_list:\n",
    "        quant_files = len(os.listdir(path))\n",
    "        count = 0\n",
    "        for file in os.listdir(path):\n",
    "            if (count / quant_files) > limit:\n",
    "                break\n",
    "            file_path = path / file\n",
    "            count += 1\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                meshs_list[path_list.index(path)].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446\n",
      "161\n",
      "810\n",
      "687\n",
      "742\n",
      "402\n"
     ]
    }
   ],
   "source": [
    "meshs_surprised = []\n",
    "meshs_disgusted = []\n",
    "meshs_happy = []\n",
    "meshs_neutral = []\n",
    "meshs_sad = []\n",
    "meshs_angry = []\n",
    "\n",
    "meshs_list = [meshs_angry, meshs_disgusted, meshs_happy, meshs_neutral, meshs_sad, meshs_surprised]\n",
    "\n",
    "extrai_dist(path_list, meshs_list, 0.1)\n",
    "\n",
    "print(len(meshs_angry))\n",
    "print(len(meshs_disgusted))\n",
    "print(len(meshs_happy))\n",
    "print(len(meshs_neutral))\n",
    "print(len(meshs_sad))\n",
    "print(len(meshs_surprised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(meshs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(meshs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target list\n",
    "target_list = []\n",
    "for i in range(6):\n",
    "    target_list.append(np.full(len(meshs_list[i]), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# print the unique target labels\n",
    "print(np.unique(np.concatenate(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3248\n"
     ]
    }
   ],
   "source": [
    "# concatena meshs_list em uma lista só\n",
    "meshs_list_concat = np.concatenate(meshs_list)\n",
    "target_list_concat = np.concatenate(target_list)\n",
    "\n",
    "print(len(meshs_list_concat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciando a construção do primeiro GINConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets, shuffling the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(meshs_list_concat, target_list_concat, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "# Split the train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import concat from tensorflow\n",
    "from tensorflow import concat\n",
    "\n",
    "# tensor_mesh = concat(meshs_list, axis=0)\n",
    "# target_tensor = concat(target_list, axis=0)\n",
    "\n",
    "X__train_tensor = concat(X_train, axis=0)\n",
    "y__train_tensor = concat(y_train, axis=0)\n",
    "\n",
    "X__val_tensor = concat(X_val, axis=0)\n",
    "y__val_tensor = concat(y_val, axis=0)\n",
    "\n",
    "X__test_tensor = concat(X_test, axis=0)\n",
    "y__test_tensor = concat(y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in target tensor:\n",
      "[0 1 2 3 4 5]\n",
      "\n",
      "Unique values in target tensor:\n",
      "[0 1 2 3 4 5]\n",
      "\n",
      "Unique values in target tensor:\n",
      "[0 1 2 3 4 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for target_tensor in [y__train_tensor, y__val_tensor, y__test_tensor]:\n",
    "    unique_values = np.unique(target_tensor.numpy())\n",
    "    print(\"Unique values in target tensor:\")\n",
    "    print(unique_values)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2630, 478, 2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor_mesh.shape\n",
    "X__train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2630])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_tensor.shape\n",
    "y__train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([293, 478, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X__val_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([293])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y__val_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 6  # Number of classes\n",
    "N = X__train_tensor.shape[-2]  # Number of nodes in the graphs\n",
    "F = X__train_tensor.shape[-1]  # Original feature dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = tf.sparse.from_dense(tf.convert_to_tensor(get_mediapipe_adjacency_matrix()))\n",
    "\n",
    "X_in = Input(shape=(N, F))\n",
    "\n",
    "graph_conv_1 = GINConv(32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True)([X_in, adj])\n",
    "graph_conv_2 = GINConv(32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True)([graph_conv_1, adj])\n",
    "flatten = Flatten()(graph_conv_2)\n",
    "fc = Dense(512, activation=\"relu\")(flatten)\n",
    "output = Dense(n_out, activation=\"softmax\")(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = Model(inputs=X_in, outputs=output)\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 478, 2)]          0         \n",
      "                                                                 \n",
      " gin_conv (GINConv)          (None, 478, 32)           97        \n",
      "                                                                 \n",
      " gin_conv_1 (GINConv)        (None, 478, 32)           1057      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15296)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               7832064   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7836296 (29.89 MB)\n",
      "Trainable params: 7836296 (29.89 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "83/83 [==============================] - 5s 50ms/step - loss: 1993.0509 - acc: 0.1981 - val_loss: 136.0345 - val_acc: 0.2594\n",
      "Epoch 2/5\n",
      "83/83 [==============================] - 4s 43ms/step - loss: 113.4394 - acc: 0.2152 - val_loss: 32.9159 - val_acc: 0.1160\n",
      "Epoch 3/5\n",
      "83/83 [==============================] - 4s 44ms/step - loss: 41.8737 - acc: 0.2384 - val_loss: 17.1881 - val_acc: 0.3413\n",
      "Epoch 4/5\n",
      "83/83 [==============================] - 4s 44ms/step - loss: 17.1835 - acc: 0.2673 - val_loss: 11.3134 - val_acc: 0.3038\n",
      "Epoch 5/5\n",
      "83/83 [==============================] - 4s 44ms/step - loss: 13.6699 - acc: 0.2681 - val_loss: 3.8753 - val_acc: 0.2560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b684cabb50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o tensor_mesh é um tensor de dimensão 3\n",
    "# o sparse_matrix é um tensor de dimensão 2\n",
    "# o target_list é um tensor de dimensão 1\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    X__train_tensor,\n",
    "    y__train_tensor,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X__val_tensor, y__val_tensor),\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(patience=es_patience)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A celua abaixo foi para verificar se não tinha inconsistencia nos inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Input ID: 6\n",
      "Real Class: 0\n",
      "Predicted Class: 3\n",
      "\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Input ID: 5\n",
      "Real Class: 1\n",
      "Predicted Class: 3\n",
      "\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Input ID: 4\n",
      "Real Class: 2\n",
      "Predicted Class: 3\n",
      "\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Input ID: 1\n",
      "Real Class: 3\n",
      "Predicted Class: 1\n",
      "\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Input ID: 0\n",
      "Real Class: 4\n",
      "Predicted Class: 3\n",
      "\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Input ID: 3\n",
      "Real Class: 5\n",
      "Predicted Class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class0startsat = None\n",
    "class1startsat = None\n",
    "class2startsat = None\n",
    "class3startsat = None\n",
    "class4startsat = None\n",
    "class5startsat = None\n",
    "\n",
    "for i in range(len(y__val_tensor)):\n",
    "    if y__val_tensor[i] == 0:\n",
    "        class0startsat = i\n",
    "        break\n",
    "\n",
    "for i in range(len(y__val_tensor)):\n",
    "    if y__val_tensor[i] == 1:\n",
    "        class1startsat = i\n",
    "        break\n",
    "\n",
    "for i in range(len(y__val_tensor)):\n",
    "    if y__val_tensor[i] == 2:\n",
    "        class2startsat = i\n",
    "        break\n",
    "\n",
    "for i in range(len(y__val_tensor)):\n",
    "    if y__val_tensor[i] == 3:\n",
    "        class3startsat = i\n",
    "        break\n",
    "\n",
    "for i in range(len(y__val_tensor)):\n",
    "    if y__val_tensor[i] == 4:\n",
    "        class4startsat = i\n",
    "        break\n",
    "\n",
    "for i in range(len(y__val_tensor)):\n",
    "    if y__val_tensor[i] == 5:\n",
    "        class5startsat = i\n",
    "        break\n",
    "\n",
    "for i in [class0startsat, class1startsat, class2startsat, class3startsat, class4startsat, class5startsat]:\n",
    "    if i is not None:\n",
    "        input_id = i\n",
    "        real_class = y__val_tensor[i].numpy()\n",
    "        predicted_class = np.argmax(model.predict(X__val_tensor[i:i+1]))\n",
    "        print(\"Input ID:\", input_id)\n",
    "        print(\"Real Class:\", real_class)\n",
    "        print(\"Predicted Class:\", predicted_class)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
