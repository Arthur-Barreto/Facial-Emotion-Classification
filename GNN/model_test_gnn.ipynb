{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 14:39:35.335055: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 14:39:35.365251: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 14:39:35.365292: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 14:39:35.366401: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 14:39:35.371100: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 14:39:35.371438: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 14:39:36.496923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# from spektral.layers import GraphConv\n",
    "# GRaphConv is deprecated, use GCNConv or GCSConv instead\n",
    "from spektral.datasets import mnist\n",
    "from spektral.layers import GatedGraphConv\n",
    "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
    "from spektral.utils import normalized_laplacian\n",
    "from spektral.layers import GCSConv  # as GraphConv\n",
    "from spektral.layers import GCNConv  # as GraphConv\n",
    "\n",
    "from spektral.utils.convolution import gcn_filter  # For GCNConv\n",
    "from spektral.utils.convolution import normalized_adjacency  # For GCSConv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "l2_reg = 5e-4  # Regularization rate for l2\n",
    "learning_rate = 1e-3  # Learning rate for SGD\n",
    "batch_size = 32  # Batch size\n",
    "epochs = 5  # Number of training epochs\n",
    "es_patience = 200  # Patience fot early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the proximiity_matrix.csv\n",
    "adj = np.loadtxt(\"adjacency_matrix.csv\", delimiter=\",\")\n",
    "print(adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega os n√≥s\n",
    "nodes = np.loadtxt(\"vertices.csv\", delimiter=\",\")\n",
    "print(nodes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega os edges\n",
    "edges = np.loadtxt(\"edges.csv\", delimiter=\",\")\n",
    "print(edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega as distancias\n",
    "y = np.loadtxt(\"distances.csv\", delimiter=\",\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria um dataframe com os dados\n",
    "df = pd.DataFrame({\"source\": edges[:, 0], \"target\": edges[:, 1], \"weight\": y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of the target\n",
    "n_out = 6\n",
    "\n",
    "N = len(nodes)  # Number of nodes in the graph\n",
    "F = 1  # Dimension of node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltr = normalized_laplacian(adj)  # For GCNConv\n",
    "# fltr = gcn_filter(adj) # For GCNConv\n",
    "# fltr = normalized_adjacency(adj) # For GCSConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://graphneural.network/layers/convolution/#gcsconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "fltr = normalized_adjacency(adj)\n",
    "\n",
    "# Model using GCSConv\n",
    "X_in = Input(shape=(N, F))\n",
    "# Pass A as a fixed tensor, otherwise Keras will complain about inputs of\n",
    "# different rank.\n",
    "A_in = Input(tensor=sp_matrix_to_sp_tensor(fltr))\n",
    "\n",
    "graph_conv_1 = GCSConv(\n",
    "    32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True\n",
    ")([X_in, A_in])\n",
    "graph_conv_2 = GCSConv(\n",
    "    32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True\n",
    ")([graph_conv_1, A_in])\n",
    "flatten = Flatten()(graph_conv_2)\n",
    "fc = Dense(512, activation=\"relu\")(flatten)\n",
    "output = Dense(n_out, activation=\"softmax\")(fc)\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, A_in], outputs=output)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the GSCConv model\n",
    "model.fit(\n",
    "    [nodes, fltr],\n",
    "    y,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(patience=es_patience, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://graphneural.network/layers/convolution/#gcnconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "fltr = gcn_filter(adj)\n",
    "# Model using GCNConv\n",
    "X_in = Input(shape=(N, F))\n",
    "# Pass A as a fixed tensor, otherwise Keras will complain about inputs of\n",
    "# different rank.\n",
    "A_in = Input(tensor=sp_matrix_to_sp_tensor(fltr))\n",
    "\n",
    "graph_conv_1 = GCNConv(\n",
    "    32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True\n",
    ")([X_in, A_in])\n",
    "graph_conv_2 = GCNConv(\n",
    "    32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True\n",
    ")([graph_conv_1, A_in])\n",
    "# removed the flatten layer because it is not necessary for GCNConv\n",
    "fc = Dense(512, activation=\"relu\")(graph_conv_2)\n",
    "output = Dense(n_out, activation=\"softmax\")(fc)\n",
    "\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, A_in], outputs=output)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the GCNConv model\n",
    "\n",
    "model.fit(\n",
    "    [nodes, fltr],\n",
    "    y,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(patience=es_patience, restore_best_weights=True)],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
