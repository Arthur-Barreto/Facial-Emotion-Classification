{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# from spektral.layers import GraphConv\n",
    "# GRaphConv is deprecated, use GCNConv or GCSConv instead\n",
    "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
    "from spektral.utils import normalized_laplacian\n",
    "from spektral.layers import GCSConv  # as GraphConv\n",
    "from spektral.layers import GINConv # as GraphConv\n",
    "from spektral.layers import GCNConv  # as GraphConv\n",
    "\n",
    "from spektral.utils.convolution import gcn_filter  # For GCNConv\n",
    "from spektral.utils.convolution import normalized_adjacency  # For GCSConv\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "l2_reg = 5e-4  # Regularization rate for l2\n",
    "learning_rate = 1e-3  # Learning rate for SGD\n",
    "batch_size = 32  # Batch size\n",
    "epochs = 5  # Number of training epochs\n",
    "es_patience = 200  # Patience fot early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = pathlib.Path().absolute()\n",
    "path = current_path.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rodri\\Documents\\Rodrigo\\Insper\\SextoSemestre\\Facial-Emotion-Classification-Graph_Fork\\angry_adj\n"
     ]
    }
   ],
   "source": [
    "# load a npz file\n",
    "# the npz file is a sparse matrix\n",
    "# as all the matrices are equal, we can use the first one is equal to all the others\n",
    "\n",
    "adj_angry_path = path / 'angry_adj'\n",
    "print(adj_angry_path)\n",
    "for file in os.listdir(adj_angry_path)[:1]:\n",
    "    file_path = adj_angry_path / file\n",
    "    sparse_matrix = scipy.sparse.load_npz(file_path)\n",
    "    sparse_matrix = sparse_matrix.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_path = path / 'angry_meshpoints'\n",
    "disgusted_path = path / 'disgusted_meshpoints'\n",
    "happy_path = path / 'happy_meshpoints'\n",
    "neutral_path = path / 'neutral_meshpoints'\n",
    "sad_path = path / 'sad_meshpoints'\n",
    "surprised_path = path / 'surprised_meshpoints'\n",
    "\n",
    "path_list = [angry_path, disgusted_path, happy_path, neutral_path, sad_path, surprised_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai_dist(path_list, dists_list, limit=0.1):\n",
    "    for path in path_list:\n",
    "        quant_files = len(os.listdir(path))\n",
    "        count = 0\n",
    "        for file in os.listdir(path):\n",
    "            if (count / quant_files) > limit:\n",
    "                break\n",
    "            file_path = path / file\n",
    "            count += 1\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                dists_list[path_list.index(path)].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446\n",
      "161\n",
      "810\n",
      "687\n",
      "742\n",
      "402\n"
     ]
    }
   ],
   "source": [
    "dists_surprised = []\n",
    "dists_disgusted = []\n",
    "dists_happy = []\n",
    "dists_neutral = []\n",
    "dists_sad = []\n",
    "dists_angry = []\n",
    "\n",
    "dists_list = [dists_angry, dists_disgusted, dists_happy, dists_neutral, dists_sad, dists_surprised]\n",
    "\n",
    "extrai_dist(path_list, dists_list, 0.1)\n",
    "\n",
    "print(len(dists_angry))\n",
    "print(len(dists_disgusted))\n",
    "print(len(dists_happy))\n",
    "print(len(dists_neutral))\n",
    "print(len(dists_sad))\n",
    "print(len(dists_surprised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dists_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import concat from tensorflow\n",
    "from tensorflow import concat\n",
    "tensor_mesh = concat(dists_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3248, 478, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mesh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target list\n",
    "target_list = []\n",
    "for i in range(6):\n",
    "    target_list.append(np.full(len(dists_list[i]), i))\n",
    "\n",
    "target_list = concat(target_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3248])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 468)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 6  # Number of classes\n",
    "N = sparse_matrix.shape[0]  # Number of nodes in the graphs\n",
    "F = tensor_mesh.shape[-1]  # Original feature dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Até aqui está exatamente como o professor sugeriu\n",
    "\n",
    "## um tensor com 3 dimensões: (número de amostras, número de vértices, número de atributos)\n",
    "## Outro com o target: (classe de cada amostra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINConv Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://graphneural.network/layers/convolution/#ginconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in = Input(shape=(N, F))\n",
    "A_in = Input(tensor=sp_matrix_to_sp_tensor(sparse_matrix)) # A as a fixed tensor, otherwise Keras will complain about inputs of different rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_conv_1 = GINConv(32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True)([X_in, A_in])\n",
    "graph_conv_2 = GINConv(32, activation=\"elu\", kernel_regularizer=l2(l2_reg), use_bias=True)([graph_conv_1, A_in])\n",
    "flatten = Flatten()(graph_conv_2)\n",
    "fc = Dense(512, activation=\"relu\")(flatten)\n",
    "output = Dense(n_out, activation=\"softmax\")(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Model(inputs=[X_in, A_in], outputs=output)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 468, 2)]             0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(468, 468)]                 0         []                            \n",
      "                                                                                                  \n",
      " gin_conv (GINConv)          (None, 468, 32)              97        ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " gin_conv_1 (GINConv)        (None, 468, 32)              1057      ['gin_conv[0][0]',            \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 14976)                0         ['gin_conv_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  7668224   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 6)                    3078      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7672456 (29.27 MB)\n",
      "Trainable params: 7672456 (29.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still need to figure out how to use the GINConv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 3248, 468\n  y sizes: 3248\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rodri\\Documents\\Rodrigo\\Insper\\SextoSemestre\\Facial-Emotion-Classification-Graph_Fork\\GNN\\model_test_gnn.ipynb Cell 23\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# o tensor_mesh é um tensor de dimensão 3\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# o sparse_matrix é um tensor de dimensão 2\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# o target_list é um tensor de dimensão 1\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m validation_data \u001b[39m=\u001b[39m ([tensor_mesh, sparse_matrix], target_list)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     [tensor_mesh, sparse_matrix],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     target_list,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     validation_data\u001b[39m=\u001b[39mvalidation_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     epochs\u001b[39m=\u001b[39mepochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     callbacks\u001b[39m=\u001b[39m[EarlyStopping(patience\u001b[39m=\u001b[39mes_patience, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rodri/Documents/Rodrigo/Insper/SextoSemestre/Facial-Emotion-Classification-Graph_Fork/GNN/model_test_gnn.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\mirror\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\mirror\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1953\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1954\u001b[0m         label,\n\u001b[0;32m   1955\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1956\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1957\u001b[0m         ),\n\u001b[0;32m   1958\u001b[0m     )\n\u001b[0;32m   1959\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1960\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3248, 468\n  y sizes: 3248\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# o tensor_mesh é um tensor de dimensão 3\n",
    "# o sparse_matrix é um tensor de dimensão 2\n",
    "# o target_list é um tensor de dimensão 1\n",
    "\n",
    "# Train model\n",
    "validation_data = ([tensor_mesh, sparse_matrix], target_list)\n",
    "model.fit(\n",
    "    [tensor_mesh, sparse_matrix],\n",
    "    target_list,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=validation_data,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(patience=es_patience, restore_best_weights=True)],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
