{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 16:28:41.398018: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 16:28:41.453150: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 16:28:41.453184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 16:28:41.454091: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 16:28:41.463645: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 16:28:41.466503: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 16:28:43.176878: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.face_mesh_connections import FACEMESH_TESSELATION\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.sparse\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_face_mes = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "face_mesh = mp_face_mes.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = cv2.imread('angry.jpeg') # read the image *** change the path to your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_frame(frame):\n",
    "    H, W, _ = frame.shape\n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results_mesh = face_mesh.process(rgb_image)\n",
    "    mesh_points=np.array([np.multiply([p.x, p.y], [W, H]).astype(int) for p in results_mesh.multi_face_landmarks[0].landmark])\n",
    "    nose_tip = mesh_points[4]\n",
    "    forehead = mesh_points[151]\n",
    "    scale_factor = np.linalg.norm(forehead - nose_tip)\n",
    "    if np.isclose(scale_factor, 0):\n",
    "        scale_factor = 1e-6\n",
    "    return results_mesh, mesh_points, scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_mesh, mesh_points, scale_factor = preprocess_frame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_grafos(results_mesh, mesh_points, scale_factor):\n",
    "    graph = nx.Graph()\n",
    "    vertices = []\n",
    "    edges = []\n",
    "    distances = []\n",
    "\n",
    "    for edge in FACEMESH_TESSELATION:\n",
    "        pointA_index = edge[0]\n",
    "        pointB_index = edge[1]\n",
    "        if [pointA_index, pointB_index] not in edges:\n",
    "            edges.append([pointA_index, pointB_index])\n",
    "            graph.add_edge(pointA_index, pointB_index)\n",
    "            x_diff = results_mesh.multi_face_landmarks[0].landmark[pointA_index].x - results_mesh.multi_face_landmarks[0].landmark[pointB_index].x\n",
    "            y_diff = results_mesh.multi_face_landmarks[0].landmark[pointA_index].y - results_mesh.multi_face_landmarks[0].landmark[pointB_index].y\n",
    "            x_diff /= scale_factor\n",
    "            y_diff /= scale_factor\n",
    "            x_diff *= 100000\n",
    "            y_diff *= 100000\n",
    "            distances.append(math.sqrt(x_diff**2 + y_diff**2))\n",
    "        if pointA_index not in vertices:\n",
    "            vertices.append(pointA_index)\n",
    "            graph.add_node(pointA_index)\n",
    "        if pointB_index not in vertices:\n",
    "            vertices.append(pointB_index)\n",
    "            graph.add_node(pointB_index)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(graph, mesh_points):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    nx.draw_networkx(graph, pos=mesh_points, node_size=10, node_color='black', edge_color='black', with_labels=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_adj(graph):\n",
    "    matrix_adj = nx.adjacency_matrix(graph)\n",
    "    sparce_matrix = scipy.sparse.csr_matrix(matrix_adj)\n",
    "    return sparce_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_adjacency_matrix(adjacency_matrix, filename):\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    print(path_name)\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    print(emotion)\n",
    "    path_name = path_name.parent.absolute()\n",
    "    print(path_name)\n",
    "    path_name = path_name.joinpath(f'{emotion}_adj')\n",
    "    print(path_name)\n",
    "    file_out = path_name.joinpath(f'{filename}.npz')\n",
    "    scipy.sparse.save_npz(file_out, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img, plot=False):\n",
    "    name = img.split('.')[0]\n",
    "    frame = cv2.imread(img)  # read the image *** change the path to your image\n",
    "    results_mesh, mesh_points, scale_factor = preprocess_frame(frame)\n",
    "    graph = gera_grafos(results_mesh, mesh_points, scale_factor)\n",
    "    adjacency_matrix = get_matrix_adj(graph)\n",
    "\n",
    "    save_adjacency_matrix(adjacency_matrix, name)\n",
    "    if plot:\n",
    "        plot_graph(graph, mesh_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_angry = 'face_angry/0.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline(\"img_angry\", plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando a pipeline para o dataset de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5017\n"
     ]
    }
   ],
   "source": [
    "### começando pelas fotos do tipo angry\n",
    "\n",
    "import pathlib\n",
    "\n",
    "actual_path = pathlib.Path().absolute()\n",
    "\n",
    "# subindo um nível\n",
    "\n",
    "path = actual_path.parent\n",
    "\n",
    "angry_path = path / 'face_angry'\n",
    "\n",
    "# constando o número de arquivos jpg\n",
    "\n",
    "import os\n",
    "\n",
    "angry_files = os.listdir(angry_path)\n",
    "\n",
    "print(len(angry_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arthur/Documentos/Insper/6_semestre/projetos_ml/projetoFinal/Facial-Emotion-Classification/face_angry\n",
      "angry\n",
      "/home/arthur/Documentos/Insper/6_semestre/projetos_ml/projetoFinal/Facial-Emotion-Classification\n",
      "/home/arthur/Documentos/Insper/6_semestre/projetos_ml/projetoFinal/Facial-Emotion-Classification/angry_adj\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for img in angry_files:\n",
    "    # img = cv2.imread(str(angry_path / img))\n",
    "    path_img = angry_path / img\n",
    "    pipeline(str(path_img), plot=False)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
